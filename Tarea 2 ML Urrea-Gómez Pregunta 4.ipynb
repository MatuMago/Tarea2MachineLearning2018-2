{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Fernanda Urrea, ROL: 201551522-0 </H3>\n",
    "<H3 align='center'> Matías Gómez, ROL: 201460501-3 </H3>\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entendimiento de imágenes de personas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de inferir ciertas características de una persona a través de una foto de ella puede resultar bastante difícil incluso para nosotros, como por ejemplo de qué país es, la emoción que expresa, la edad que tiene, o el género. La automatización de este proceso para que máquinas logren identificar ciertas características de una persona puede ser algo crucial para el futuro desarrollo de Inteligencia Artificial.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/6B072GE.jpg\" width=\"60%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con unos datos (imágenes) con la tarea de predecir la **edad** (*target value*) de la persona en la imagen. Los datos con corresponden a 3640 imágenes de Flickr de rostros de personas, pero para simplificar el manejo y cómputo, se trabajará con representaciones de características extraídas (descriptores). Para ésto necesitará descargar los datos del siguiente __[link](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)__ en el extracto de *ageGenderClassification* o a través de la consola Unix.\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/ageGenderClassification.zip\n",
    "```\n",
    "\n",
    "Se trabajará con archivos *.mat* que pueden ser cargados de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import scipy.io as sio\n",
    "sio.loadmat(\"file.mat\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descripción sobre las columnas y metadatos del archivo descargado favor dirigirse al archivo readme a través del siguiente __[link](http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt)__ o a través de la consola Unix:\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt\n",
    "```\n",
    "En el apartado \"*MATLAB DATA*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Cargue los datos dos dataset de entrenamiento y de pruebas ¿Cuántos datos hay en cada conjunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "mat_train = sio.loadmat(\"./AgeGenderClassification/eventrain.mat\")\n",
    "mat_test = sio.loadmat(\"./AgeGenderClassification/eventest.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 14)\n",
      "[42.         34.          3.          0.98386991  6.         -0.36363636\n",
      "  0.1798535  -0.          1.04286927 -3.49598221  0.11850787  1.04375052\n",
      "  1.          5.        ]\n",
      "(1050, 14)\n",
      "[87.         35.          1.          1.11803399  4.15908644  0.26832816\n",
      " -0.         -0.1798535   1.0615004  16.11449821 -2.21822498  1.09343236\n",
      "  1.          5.        ]\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(data_train[0])\n",
    "print(data_test.shape)\n",
    "print(data_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de entranamiento contiene 3.500 ejemplos, y cada ejemplo es una 14-tupla de números.  \n",
    "El dataset de pruebas contiene 1.050 ejemplos, y cada ejemplo es una 14-tupla de números.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Elija cuál representación utilizará para trabajar los datos y entregárselos como *input* al modelo de aprendizaje a utilizar, recuerde que puede utilizar una combinación de éstos si lo desea. Además extraiga las salidas/*output* del problema, en este caso, como ya se comentó, la edad. Describa los datos utilizados y la cantidad de datos por rango de edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) 34\n",
      "(3500, 3) [42.          3.          0.98386991]\n",
      "(1050,) 35\n",
      "(1050, 3) [87.          1.          1.11803399]\n"
     ]
    }
   ],
   "source": [
    "#genFeat = data[0]  #it can be used as representation: contextual features\n",
    "#ageClass = data[1] #target\n",
    "#ffcoefs = data[3]   #it can be used as representation: fisherface space\n",
    "#faceGist = data[4]  #it can be used as representation: face\n",
    "\n",
    "#Se utilizaran los 3 atributos presentados antes\n",
    "#Se crean los conjuntos de prueba inputs y outputs\n",
    "import numpy as np;\n",
    "\n",
    "Y_train=[];\n",
    "X_train=[];\n",
    "Y_test=[];\n",
    "X_test=[];\n",
    "\n",
    "for i in range(3500):\n",
    "    Y_train.append(int(data_train[i][1]));\n",
    "    l=[];\n",
    "    l.append(data_train[i][0]);\n",
    "    l.append(data_train[i][2]);\n",
    "    l.append(data_train[i][3]);\n",
    "    X_train.append(l);\n",
    "    if i<1050:\n",
    "        Y_test.append(int(data_test[i][1]));\n",
    "        l=[];\n",
    "        l.append(data_test[i][0]);\n",
    "        l.append(data_test[i][2]);\n",
    "        l.append(data_test[i][3]);\n",
    "        X_test.append(l);\n",
    "        \n",
    "Y_train=np.asarray(Y_train);\n",
    "X_train=np.asarray(X_train);\n",
    "Y_test=np.asarray(Y_test);\n",
    "X_test=np.asarray(X_test);\n",
    "\n",
    "print(Y_train.shape,Y_train[0]);\n",
    "print(X_train.shape,X_train[0]);\n",
    "print(Y_test.shape,Y_test[0]);\n",
    "print(X_test.shape,X_test[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean los conjuntos de entrenamiento y pruebas.  \n",
    "X_train tiene 3.500 ejemplos con 3 atributos cada uno.  \n",
    "Y_train contiene las 3.500 edades que corresponden a los 3.500 ejemplos.  \n",
    "X_test tiene 1.050 ejemplos con 3 atributos cada uno.  \n",
    "Y_test contiene las 1.050 edades que corresponden a los 1.050 ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  1]\n",
      " [ 6  6]\n",
      " [ 7  3]\n",
      " [ 8  6]\n",
      " [ 9 12]\n",
      " [10 19]\n",
      " [11 15]\n",
      " [12 20]\n",
      " [13 20]\n",
      " [14 33]\n",
      " [15 38]\n",
      " [16 41]\n",
      " [17 43]\n",
      " [18 62]\n",
      " [19 54]\n",
      " [20 58]\n",
      " [21 76]\n",
      " [22 62]\n",
      " [23 64]\n",
      " [24 82]\n",
      " [25 78]\n",
      " [26 69]\n",
      " [27 74]\n",
      " [28 53]\n",
      " [29 89]\n",
      " [30 67]\n",
      " [31 67]\n",
      " [32 78]\n",
      " [33 59]\n",
      " [34 68]\n",
      " [35 75]\n",
      " [36 65]\n",
      " [37 71]\n",
      " [38 75]\n",
      " [39 70]\n",
      " [40 78]\n",
      " [41 71]\n",
      " [42 78]\n",
      " [43 49]\n",
      " [44 62]\n",
      " [45 64]\n",
      " [46 75]\n",
      " [47 58]\n",
      " [48 57]\n",
      " [49 71]\n",
      " [50 71]\n",
      " [51 57]\n",
      " [52 65]\n",
      " [53 59]\n",
      " [54 62]\n",
      " [55 58]\n",
      " [56 49]\n",
      " [57 49]\n",
      " [58 42]\n",
      " [59 48]\n",
      " [60 47]\n",
      " [61 34]\n",
      " [62 33]\n",
      " [63 37]\n",
      " [64 32]\n",
      " [65 34]\n",
      " [66 24]\n",
      " [67 33]\n",
      " [68 31]\n",
      " [69 21]\n",
      " [70 27]\n",
      " [71 23]\n",
      " [72 12]\n",
      " [73 18]\n",
      " [74 13]\n",
      " [75 15]\n",
      " [76 10]\n",
      " [77  8]\n",
      " [78 10]\n",
      " [79  6]\n",
      " [80  7]\n",
      " [81  5]\n",
      " [82  3]\n",
      " [83  1]\n",
      " [84  5]\n",
      " [85  1]\n",
      " [86  3]\n",
      " [87  4]\n",
      " [88  3]\n",
      " [89  1]\n",
      " [90  1]\n",
      " [91  1]\n",
      " [97  1]] \n",
      "\n",
      " [[ 6  1]\n",
      " [ 7  3]\n",
      " [ 8  2]\n",
      " [ 9  5]\n",
      " [10  9]\n",
      " [11  7]\n",
      " [12 11]\n",
      " [13  4]\n",
      " [14  5]\n",
      " [15  8]\n",
      " [16 15]\n",
      " [17 12]\n",
      " [18 17]\n",
      " [19 20]\n",
      " [20 17]\n",
      " [21 14]\n",
      " [22 13]\n",
      " [23 16]\n",
      " [24 15]\n",
      " [25 16]\n",
      " [26 19]\n",
      " [27 21]\n",
      " [28 22]\n",
      " [29 20]\n",
      " [30 20]\n",
      " [31 25]\n",
      " [32 21]\n",
      " [33 14]\n",
      " [34 25]\n",
      " [35 28]\n",
      " [36 23]\n",
      " [37 26]\n",
      " [38 21]\n",
      " [39 17]\n",
      " [40 25]\n",
      " [41 22]\n",
      " [42 29]\n",
      " [43 20]\n",
      " [44 27]\n",
      " [45 22]\n",
      " [46 25]\n",
      " [47 26]\n",
      " [48 15]\n",
      " [49 18]\n",
      " [50 15]\n",
      " [51 10]\n",
      " [52 18]\n",
      " [53  8]\n",
      " [54 15]\n",
      " [55 11]\n",
      " [56 15]\n",
      " [57 16]\n",
      " [58 16]\n",
      " [59 15]\n",
      " [60 18]\n",
      " [61 19]\n",
      " [62 21]\n",
      " [63  8]\n",
      " [64 11]\n",
      " [65  9]\n",
      " [66 11]\n",
      " [67 10]\n",
      " [68  8]\n",
      " [69  7]\n",
      " [70  8]\n",
      " [71  7]\n",
      " [72  6]\n",
      " [73  2]\n",
      " [74  2]\n",
      " [75  3]\n",
      " [76  4]\n",
      " [77  4]\n",
      " [78  2]\n",
      " [79  2]\n",
      " [80  1]\n",
      " [81  3]\n",
      " [83  1]\n",
      " [86  1]\n",
      " [91  1]\n",
      " [93  1]]\n"
     ]
    }
   ],
   "source": [
    "cantidad_edades_train = np.bincount(Y_train);\n",
    "numeros_edades_train = np.nonzero(cantidad_edades_train)[0];\n",
    "#Arreglo de listas de dos elementos donde el primero es la edad y el segundo la cantidad\n",
    "arreglo_train=np.vstack((numeros_edades_train,cantidad_edades_train[numeros_edades_train])).T; \n",
    "\n",
    "cantidad_edades_test = np.bincount(Y_test);\n",
    "numeros_edades_test = np.nonzero(cantidad_edades_test)[0];\n",
    "#Arreglo de listas de dos elementos donde el primero es la edad y el segundo la cantidad\n",
    "arreglo_test=np.vstack((numeros_edades_test,cantidad_edades_test[numeros_edades_test])).T;\n",
    "\n",
    "print(arreglo_train,\"\\n\\n\",arreglo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crearon arreglos, en los que se detallan edades exactas y cantidad de ejemplos para cada edad en los conjuntos de entrenamiento y prueba.  \n",
    "A continuación, se convertirán las edades en los rangos que se detallan en el documento README.txt del enunciado, es decir:  \n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "\\begin{eqnarray}\n",
    "&{\\textbf{Etiqueta}}\\\\ & 1 \\\\ & 5\\\\ & 10\\\\ & 16\\\\ & 28\\\\ & 51\\\\ & 75\\\\\n",
    "\\end{eqnarray}\n",
    "        </td>\n",
    "        <td>\n",
    "\\begin{eqnarray}\n",
    "&{\\textbf{Rango etario}}\\\\& 0-2 \\\\ & 3-7\\\\ & 8-12\\\\ & 13-19\\\\ & 20-36\\\\ & 37-65\\\\ & 66+\\\\\n",
    "\\end{eqnarray}\n",
    "        </td>\n",
    "\n",
    "\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3500):\n",
    "    if Y_train[i]<3:\n",
    "        Y_train[i]=1;\n",
    "    elif Y_train[i]<8:\n",
    "        Y_train[i]=5;\n",
    "    elif Y_train[i]<13:\n",
    "        Y_train[i]=10;\n",
    "    elif Y_train[i]<20:\n",
    "        Y_train[i]=16;\n",
    "    elif Y_train[i]<37:\n",
    "        Y_train[i]=28;\n",
    "    elif Y_train[i]<66:\n",
    "        Y_train[i]=51;\n",
    "    else:\n",
    "        Y_train[i]=75;\n",
    "    if i<1050:\n",
    "        if Y_test[i]<3:\n",
    "            Y_test[i]=1;\n",
    "        elif Y_test[i]<8:\n",
    "            Y_test[i]=5;\n",
    "        elif Y_test[i]<13:\n",
    "            Y_test[i]=10;\n",
    "        elif Y_test[i]<20:\n",
    "            Y_test[i]=16;\n",
    "        elif Y_test[i]<37:\n",
    "            Y_test[i]=28;\n",
    "        elif Y_test[i]<66:\n",
    "            Y_test[i]=51;\n",
    "        else:\n",
    "            Y_test[i]=75;\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   5   10]\n",
      " [  10   72]\n",
      " [  16  291]\n",
      " [  28 1184]\n",
      " [  51 1656]\n",
      " [  75  287]] \n",
      "\n",
      " [[  5   4]\n",
      " [ 10  34]\n",
      " [ 16  81]\n",
      " [ 28 329]\n",
      " [ 51 518]\n",
      " [ 75  84]]\n"
     ]
    }
   ],
   "source": [
    "cantidad_edades_trainNew = np.bincount(Y_train);\n",
    "numeros_edades_trainNew = np.nonzero(cantidad_edades_trainNew)[0];\n",
    "#Arreglo de listas de dos elementos donde el primero es la edad y el segundo la cantidad\n",
    "arreglo_trainNew=np.vstack((numeros_edades_trainNew,cantidad_edades_trainNew[numeros_edades_trainNew])).T; \n",
    "\n",
    "cantidad_edades_testNew = np.bincount(Y_test);\n",
    "numeros_edades_testNew = np.nonzero(cantidad_edades_testNew)[0];\n",
    "#Arreglo de listas de dos elementos donde el primero es la edad y el segundo la cantidad\n",
    "arreglo_testNew=np.vstack((numeros_edades_testNew,cantidad_edades_testNew[numeros_edades_testNew])).T;\n",
    "\n",
    "print(arreglo_trainNew,\"\\n\\n\",arreglo_testNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, los outputs del conjunto de $\\textbf{entrenamiento}$ quedan:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "\\begin{eqnarray}\n",
    "&{\\textbf{Etiqueta}}\\\\  & 5\\\\ & 10\\\\ & 16\\\\ & 28\\\\ & 51\\\\ & 75\\\\\n",
    "\\end{eqnarray}\n",
    "        </td>\n",
    "        <td>\n",
    "\\begin{eqnarray}\n",
    "&{\\textbf{Cantidad}}\\\\& 10 \\\\ & 72\\\\ & 291\\\\ & 1184\\\\ & 1656\\\\ & 287\\\\\n",
    "\\end{eqnarray}\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "  \n",
    "Y los outputs del conjunto de $\\textbf{pruebas}$ quedan:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "\\begin{eqnarray}\n",
    "&{\\textbf{Etiqueta}}\\\\  & 5\\\\ & 10\\\\ & 16\\\\ & 28\\\\ & 51\\\\ & 75\\\\\n",
    "\\end{eqnarray}\n",
    "        </td>\n",
    "        <td>\n",
    "\\begin{eqnarray}\n",
    "&{\\textbf{Cantidad}}\\\\& 4 \\\\ & 34\\\\ & 81\\\\ & 329\\\\ & 518\\\\ & 84\\\\\n",
    "\\end{eqnarray}\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Defina y entrene modelos de aprendizaje para la inferencia de la edad de la persona a través de la representación escogida, *se espera que experimente con distintas configuraciones, modelos e hiper-parámetros* . Intente llegar a un *MSE* menor a 100 sobre la edad de las personas en el conjunto de pruebas. Recuerde que **NO** puede seleccionar modelos a través del conjunto de pruebas. Visualice sus resultados si estima conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota: Puede notar que la cantidad de edades presentes en el problema son pocas (1,  5, 10, 16, 28, 51 o 75 años), por lo que puede tratar al problema así como de regresión o clasificación (considerando cada edad como una clase)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se considerará el problema como uno de clasificación asignando cada edad como una clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "X_train_scaled = std.transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a crear una representación de las clases etiquetándolas de $0$ a $6$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [4 2 4 ... 5 6 5]\n"
     ]
    }
   ],
   "source": [
    "Y_train_codif=[];\n",
    "Y_test_codif=[];\n",
    "for i in range(3500):\n",
    "    if Y_train[i]==1:\n",
    "        Y_train_codif.append(0)\n",
    "    if Y_train[i]==5:\n",
    "        Y_train_codif.append(1)        \n",
    "    if Y_train[i]==10:\n",
    "        Y_train_codif.append(2)  \n",
    "    if Y_train[i]==16:\n",
    "        Y_train_codif.append(3)  \n",
    "    if Y_train[i]==28:\n",
    "        Y_train_codif.append(4)  \n",
    "    if Y_train[i]==51:\n",
    "        Y_train_codif.append(5)  \n",
    "    if Y_train[i]==75:\n",
    "        Y_train_codif.append(6)  \n",
    "    if i<1050:\n",
    "        if Y_test[i]==1:\n",
    "            Y_test_codif.append(0)\n",
    "        if Y_test[i]==5:\n",
    "            Y_test_codif.append(1)        \n",
    "        if Y_test[i]==10:\n",
    "            Y_test_codif.append(2)  \n",
    "        if Y_test[i]==16:\n",
    "            Y_test_codif.append(3)  \n",
    "        if Y_test[i]==28:\n",
    "            Y_test_codif.append(4)  \n",
    "        if Y_test[i]==51:\n",
    "            Y_test_codif.append(5)  \n",
    "        if Y_test[i]==75:\n",
    "            Y_test_codif.append(6) \n",
    "Y_train_codif=np.asarray(Y_train_codif);\n",
    "Y_test_codif=np.asarray(Y_test_codif);\n",
    "print(Y_train_codif.shape,Y_train_codif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a la representaicón anterior, se construye con ayuda de keras una representación $\\textit{one hot vector}$. Luego se presentan algunos ejemplos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "y_onehot_train = keras.utils.to_categorical(Y_train_codif,num_classes=7)\n",
    "y_onehot_test = keras.utils.to_categorical(Y_test_codif,num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0.] 28\n",
      "[0. 0. 0. 0. 0. 1. 0.] 51\n",
      "[0. 0. 0. 0. 1. 0. 0.] 28\n",
      "[0. 0. 0. 0. 1. 0. 0.] 28\n",
      "[0. 0. 0. 0. 1. 0. 0.] 28\n",
      "[0. 0. 0. 0. 1. 0. 0.] 28\n",
      "[0. 0. 0. 1. 0. 0. 0.] 16\n",
      "[0. 0. 0. 0. 0. 1. 0.] 51\n",
      "[0. 0. 0. 0. 0. 1. 0.] 51\n",
      "[0. 0. 0. 0. 1. 0. 0.] 28\n"
     ]
    }
   ],
   "source": [
    "print(y_onehot_train[0], Y_train[0]);\n",
    "print(y_onehot_train[20],  Y_train[20]);\n",
    "print(y_onehot_train[40],  Y_train[40]);\n",
    "print(y_onehot_train[60],  Y_train[60]);\n",
    "print(y_onehot_train[100],  Y_train[100]);\n",
    "print(y_onehot_test[0], Y_test[0]);\n",
    "print(y_onehot_test[20], Y_test[20]);\n",
    "print(y_onehot_test[40], Y_test[40]);\n",
    "print(y_onehot_test[60], Y_test[60]);\n",
    "print(y_onehot_test[100], Y_test[100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el problema es de clasificación, utilizaremos una red neuronal de modelo $\\textit{sequential}$, pero a diferencia de la pregunta 2, la función de activación será $\\textit{softmax}$ y la función de pérdida $\\textit{categorical_crossentropy}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 1s 232us/step - loss: 1.5137\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.2355\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.2031\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1915\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1861\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1827\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1808\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1801\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1780\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1757\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1749\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1737\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1758\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1738\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1732\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1729\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1751\n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1745\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.1706\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1701\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1715\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1698\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 0s 28us/step - loss: 1.1741\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1690\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1716\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1694\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1686\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1695\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1684\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1687\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 0s 42us/step - loss: 1.1683\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 0s 37us/step - loss: 1.1689\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1658\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.1670\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1669\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.1672\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1663\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1656\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1666\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1660\n",
      "--- 5.79590916633606 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=40, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a trabajar los output de la red neuronal para volverlos al formato original, con el fin de poder calcular el error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_nn=model.predict(X_train_scaled);\n",
    "y_pred_test_nn=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [28 51 51 ... 51 51 51] [28 10 28 ... 51 75 51]\n",
      "(1050,) [28 51 51 ... 51 51 51] [28 51 51 ... 51 51 10]\n"
     ]
    }
   ],
   "source": [
    "#print(len(y_pred_train_nn),len(y_pred_test_nn))\n",
    "def f(x):\n",
    "    if x==0:\n",
    "        return 1;\n",
    "    elif x==1:\n",
    "        return 5;\n",
    "    elif x==2:\n",
    "        return 10;\n",
    "    elif x==3:\n",
    "        return 16;\n",
    "    elif x==4:\n",
    "        return 28;\n",
    "    elif x==5:\n",
    "        return 51;\n",
    "    elif x==6:\n",
    "        return 75;\n",
    "\n",
    "\n",
    "y_pred_train_nn_etiquetas=[];\n",
    "y_pred_test_nn_etiquetas=[];\n",
    "#print(len(y_pred_train_nn[0]))\n",
    "for i in range(3500):\n",
    "    posMax=6;\n",
    "    valMax=y_pred_train_nn[i][6]\n",
    "    for j in range(6):\n",
    "        if y_pred_train_nn[i][j] > valMax:\n",
    "            valMax=y_pred_train_nn[i][j];\n",
    "            posMax=j;\n",
    "            \n",
    "    y_pred_train_nn_etiquetas.append(f(posMax));\n",
    "    if i < 1050:\n",
    "        posMax=6;\n",
    "        valMax=y_pred_test_nn[i][6]\n",
    "        for j in range(6):\n",
    "            if y_pred_test_nn[i][j] > valMax:\n",
    "                valMax=y_pred_test_nn[i][j];\n",
    "                posMax=j;\n",
    "        y_pred_test_nn_etiquetas.append(f(posMax));   \n",
    "        \n",
    "y_pred_train_nn_etiquetas=np.asarray(y_pred_train_nn_etiquetas);\n",
    "y_pred_test_nn_etiquetas=np.asarray(y_pred_test_nn_etiquetas);\n",
    "\n",
    "print(y_pred_train_nn_etiquetas.shape,y_pred_train_nn_etiquetas,Y_train);\n",
    "print(y_pred_test_nn_etiquetas.shape,y_pred_test_nn_etiquetas, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  347.50142857142856\n",
      "ERROR MSE de test:  359.18857142857144\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_nn_etiquetas))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_nn_etiquetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probaremos con la misma red neuronal cambiando el optimizador, de Adam a el usado en la pregunta 2, SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 1s 221us/step - loss: 1.4862\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.2542\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 0s 32us/step - loss: 1.2223\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.2093\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 0s 33us/step - loss: 1.2016\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1960\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 0s 34us/step - loss: 1.1915\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1876\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1860\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1832\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1817\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1793\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1790\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1789\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1770\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1768\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1778\n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1762\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1742\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1731\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 0s 33us/step - loss: 1.1746\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1724\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1726\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1713\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1726\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1712\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 0s 26us/step - loss: 1.1724\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1714\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1722\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 0s 33us/step - loss: 1.1706\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1707\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 0s 32us/step - loss: 1.1691\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1701\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1697\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1695\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1694\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1695\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1689\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.1703\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.1706\n",
      "--- 5.240979909896851 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=SGD(lr=0.1), loss=\"categorical_crossentropy\")\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=40, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a trabajar los output de la red neuronal para volverlos al formato original, con el fin de poder calcular el error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_nn=model.predict(X_train_scaled);\n",
    "y_pred_test_nn=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [51 51 51 ... 51 51 51] [28 10 28 ... 51 75 51]\n",
      "(1050,) [28 51 51 ... 51 51 51] [28 51 51 ... 51 51 10]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x==0:\n",
    "        return 1;\n",
    "    elif x==1:\n",
    "        return 5;\n",
    "    elif x==2:\n",
    "        return 10;\n",
    "    elif x==3:\n",
    "        return 16;\n",
    "    elif x==4:\n",
    "        return 28;\n",
    "    elif x==5:\n",
    "        return 51;\n",
    "    elif x==6:\n",
    "        return 75;\n",
    "\n",
    "\n",
    "y_pred_train_nn_etiquetas=[];\n",
    "y_pred_test_nn_etiquetas=[];\n",
    "#print(len(y_pred_train_nn[0]))\n",
    "for i in range(3500):\n",
    "    posMax=6;\n",
    "    valMax=y_pred_train_nn[i][6]\n",
    "    for j in range(6):\n",
    "        if y_pred_train_nn[i][j] > valMax:\n",
    "            valMax=y_pred_train_nn[i][j];\n",
    "            posMax=j;\n",
    "            \n",
    "    y_pred_train_nn_etiquetas.append(f(posMax));\n",
    "    if i < 1050:\n",
    "        posMax=6;\n",
    "        valMax=y_pred_test_nn[i][6]\n",
    "        for j in range(6):\n",
    "            if y_pred_test_nn[i][j] > valMax:\n",
    "                valMax=y_pred_test_nn[i][j];\n",
    "                posMax=j;\n",
    "        y_pred_test_nn_etiquetas.append(f(posMax));   \n",
    "        \n",
    "y_pred_train_nn_etiquetas=np.asarray(y_pred_train_nn_etiquetas);\n",
    "y_pred_test_nn_etiquetas=np.asarray(y_pred_test_nn_etiquetas);\n",
    "\n",
    "print(y_pred_train_nn_etiquetas.shape,y_pred_train_nn_etiquetas,Y_train);\n",
    "print(y_pred_test_nn_etiquetas.shape,y_pred_test_nn_etiquetas, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  358.95542857142857\n",
      "ERROR MSE de test:  364.7085714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_nn_etiquetas))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_nn_etiquetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se variarán los parámetros de fit, en particular la cantidad de veces que se entrena, epochs de $40$ a $15$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3500/3500 [==============================] - 1s 312us/step - loss: 1.5524\n",
      "Epoch 2/15\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.2395\n",
      "Epoch 3/15\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.2069\n",
      "Epoch 4/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 1.204 - 0s 45us/step - loss: 1.1924\n",
      "Epoch 5/15\n",
      "3500/3500 [==============================] - 0s 42us/step - loss: 1.1885\n",
      "Epoch 6/15\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1865\n",
      "Epoch 7/15\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1804\n",
      "Epoch 8/15\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1808\n",
      "Epoch 9/15\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1776\n",
      "Epoch 10/15\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.1797\n",
      "Epoch 11/15\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1746\n",
      "Epoch 12/15\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1759\n",
      "Epoch 13/15\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.1765\n",
      "Epoch 14/15\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1760\n",
      "Epoch 15/15\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1739\n",
      "--- 3.734560966491699 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=15, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_nn=model.predict(X_train_scaled);\n",
    "y_pred_test_nn=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [28 51 51 ... 51 51 51] [28 10 28 ... 51 75 51]\n",
      "(1050,) [28 51 51 ... 51 51 51] [28 51 51 ... 51 51 10]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x==0:\n",
    "        return 1;\n",
    "    elif x==1:\n",
    "        return 5;\n",
    "    elif x==2:\n",
    "        return 10;\n",
    "    elif x==3:\n",
    "        return 16;\n",
    "    elif x==4:\n",
    "        return 28;\n",
    "    elif x==5:\n",
    "        return 51;\n",
    "    elif x==6:\n",
    "        return 75;\n",
    "\n",
    "\n",
    "y_pred_train_nn_etiquetas=[];\n",
    "y_pred_test_nn_etiquetas=[];\n",
    "#print(len(y_pred_train_nn[0]))\n",
    "for i in range(3500):\n",
    "    posMax=6;\n",
    "    valMax=y_pred_train_nn[i][6]\n",
    "    for j in range(6):\n",
    "        if y_pred_train_nn[i][j] > valMax:\n",
    "            valMax=y_pred_train_nn[i][j];\n",
    "            posMax=j;\n",
    "            \n",
    "    y_pred_train_nn_etiquetas.append(f(posMax));\n",
    "    if i < 1050:\n",
    "        posMax=6;\n",
    "        valMax=y_pred_test_nn[i][6]\n",
    "        for j in range(6):\n",
    "            if y_pred_test_nn[i][j] > valMax:\n",
    "                valMax=y_pred_test_nn[i][j];\n",
    "                posMax=j;\n",
    "        y_pred_test_nn_etiquetas.append(f(posMax));   \n",
    "        \n",
    "y_pred_train_nn_etiquetas=np.asarray(y_pred_train_nn_etiquetas);\n",
    "y_pred_test_nn_etiquetas=np.asarray(y_pred_test_nn_etiquetas);\n",
    "\n",
    "print(y_pred_train_nn_etiquetas.shape,y_pred_train_nn_etiquetas,Y_train);\n",
    "print(y_pred_test_nn_etiquetas.shape,y_pred_test_nn_etiquetas, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  341.114\n",
      "ERROR MSE de test:  348.1485714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_nn_etiquetas))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_nn_etiquetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se varian los parámetros de $Dense$ referentes a la cantidad de neuronas ocultas, primero con valores prqueños, luego con valores más grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 1s 342us/step - loss: 1.8693\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.7346\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.6096\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.4970\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.4065\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.3442\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.3031\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.2764\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 0s 30us/step - loss: 1.2576\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.2440\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.2335\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.2255\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 0s 29us/step - loss: 1.2186\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.2140\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.2089\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.2052\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.2024\n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.2002\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1973\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1953\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1936\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1922\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1908\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1893\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1884\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 0s 28us/step - loss: 1.1874\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1871\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1858\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1842\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1837\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1834\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1825\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1818\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1821\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1813\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 0s 24us/step - loss: 1.1806\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 0s 27us/step - loss: 1.1799\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 0s 22us/step - loss: 1.1795\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 0s 25us/step - loss: 1.1796\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 0s 26us/step - loss: 1.1787\n",
      "--- 5.469008445739746 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=40, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_nn=model.predict(X_train_scaled);\n",
    "y_pred_test_nn=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [28 51 51 ... 51 51 51] [28 10 28 ... 51 75 51]\n",
      "(1050,) [51 51 51 ... 51 51 51] [28 51 51 ... 51 51 10]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x==0:\n",
    "        return 1;\n",
    "    elif x==1:\n",
    "        return 5;\n",
    "    elif x==2:\n",
    "        return 10;\n",
    "    elif x==3:\n",
    "        return 16;\n",
    "    elif x==4:\n",
    "        return 28;\n",
    "    elif x==5:\n",
    "        return 51;\n",
    "    elif x==6:\n",
    "        return 75;\n",
    "\n",
    "\n",
    "y_pred_train_nn_etiquetas=[];\n",
    "y_pred_test_nn_etiquetas=[];\n",
    "#print(len(y_pred_train_nn[0]))\n",
    "for i in range(3500):\n",
    "    posMax=6;\n",
    "    valMax=y_pred_train_nn[i][6]\n",
    "    for j in range(6):\n",
    "        if y_pred_train_nn[i][j] > valMax:\n",
    "            valMax=y_pred_train_nn[i][j];\n",
    "            posMax=j;\n",
    "            \n",
    "    y_pred_train_nn_etiquetas.append(f(posMax));\n",
    "    if i < 1050:\n",
    "        posMax=6;\n",
    "        valMax=y_pred_test_nn[i][6]\n",
    "        for j in range(6):\n",
    "            if y_pred_test_nn[i][j] > valMax:\n",
    "                valMax=y_pred_test_nn[i][j];\n",
    "                posMax=j;\n",
    "        y_pred_test_nn_etiquetas.append(f(posMax));   \n",
    "        \n",
    "y_pred_train_nn_etiquetas=np.asarray(y_pred_train_nn_etiquetas);\n",
    "y_pred_test_nn_etiquetas=np.asarray(y_pred_test_nn_etiquetas);\n",
    "\n",
    "print(y_pred_train_nn_etiquetas.shape,y_pred_train_nn_etiquetas,Y_train);\n",
    "print(y_pred_test_nn_etiquetas.shape,y_pred_test_nn_etiquetas, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  349.93285714285713\n",
      "ERROR MSE de test:  349.4847619047619\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_nn_etiquetas))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_nn_etiquetas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 3s 749us/step - loss: 1.3277\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 2s 436us/step - loss: 1.2051 0s - los\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 2s 499us/step - loss: 1.1907\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 2s 519us/step - loss: 1.1900\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 2s 463us/step - loss: 1.1989\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 2s 452us/step - loss: 1.1889\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 2s 506us/step - loss: 1.1805\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 1s 423us/step - loss: 1.1769\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 1s 394us/step - loss: 1.1790\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 1s 371us/step - loss: 1.1753\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 1s 366us/step - loss: 1.1775\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 1s 378us/step - loss: 1.1761\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 1s 386us/step - loss: 1.1763\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 1s 423us/step - loss: 1.1721\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 2s 479us/step - loss: 1.1729\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 2s 571us/step - loss: 1.1785\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 2s 436us/step - loss: 1.1718 0s - loss: \n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 2s 560us/step - loss: 1.1718\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 2s 525us/step - loss: 1.1762\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 2s 506us/step - loss: 1.1701\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 2s 490us/step - loss: 1.1704\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 2s 440us/step - loss: 1.1693\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 2s 550us/step - loss: 1.1723\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 1s 411us/step - loss: 1.1712\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 1.173 - 1s 411us/step - loss: 1.1732\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 1s 421us/step - loss: 1.1654\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 1s 420us/step - loss: 1.1710\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 1s 407us/step - loss: 1.1676\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 1s 402us/step - loss: 1.1674\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 1s 406us/step - loss: 1.1669\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 1s 384us/step - loss: 1.1654\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 1s 408us/step - loss: 1.1654\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 1s 400us/step - loss: 1.1633\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 1s 383us/step - loss: 1.1655\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 1s 391us/step - loss: 1.1650\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 1s 397us/step - loss: 1.1636\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 1s 423us/step - loss: 1.1654\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 1s 402us/step - loss: 1.1635\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 1s 424us/step - loss: 1.1675\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 1s 402us/step - loss: 1.1602\n",
      "--- 63.22129535675049 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=40, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_nn=model.predict(X_train_scaled);\n",
    "y_pred_test_nn=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [51 51 51 ... 51 51 51] [28 10 28 ... 51 75 51]\n",
      "(1050,) [28 51 51 ... 51 51 51] [28 51 51 ... 51 51 10]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x==0:\n",
    "        return 1;\n",
    "    elif x==1:\n",
    "        return 5;\n",
    "    elif x==2:\n",
    "        return 10;\n",
    "    elif x==3:\n",
    "        return 16;\n",
    "    elif x==4:\n",
    "        return 28;\n",
    "    elif x==5:\n",
    "        return 51;\n",
    "    elif x==6:\n",
    "        return 75;\n",
    "\n",
    "\n",
    "y_pred_train_nn_etiquetas=[];\n",
    "y_pred_test_nn_etiquetas=[];\n",
    "#print(len(y_pred_train_nn[0]))\n",
    "for i in range(3500):\n",
    "    posMax=6;\n",
    "    valMax=y_pred_train_nn[i][6]\n",
    "    for j in range(6):\n",
    "        if y_pred_train_nn[i][j] > valMax:\n",
    "            valMax=y_pred_train_nn[i][j];\n",
    "            posMax=j;\n",
    "            \n",
    "    y_pred_train_nn_etiquetas.append(f(posMax));\n",
    "    if i < 1050:\n",
    "        posMax=6;\n",
    "        valMax=y_pred_test_nn[i][6]\n",
    "        for j in range(6):\n",
    "            if y_pred_test_nn[i][j] > valMax:\n",
    "                valMax=y_pred_test_nn[i][j];\n",
    "                posMax=j;\n",
    "        y_pred_test_nn_etiquetas.append(f(posMax));   \n",
    "        \n",
    "y_pred_train_nn_etiquetas=np.asarray(y_pred_train_nn_etiquetas);\n",
    "y_pred_test_nn_etiquetas=np.asarray(y_pred_test_nn_etiquetas);\n",
    "\n",
    "print(y_pred_train_nn_etiquetas.shape,y_pred_train_nn_etiquetas,Y_train);\n",
    "print(y_pred_test_nn_etiquetas.shape,y_pred_test_nn_etiquetas, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  350.3468571428571\n",
      "ERROR MSE de test:  357.0419047619048\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_nn_etiquetas))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_nn_etiquetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregando $ metrics=[\"acc\"]$ a los parámetros de compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 1s 395us/step - loss: 1.4930 - acc: 0.4477\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.2327 - acc: 0.4709\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 0s 38us/step - loss: 1.2038 - acc: 0.4734\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.1972 - acc: 0.4620\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 0s 43us/step - loss: 1.1888 - acc: 0.4706\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 0s 37us/step - loss: 1.1851 - acc: 0.4817\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 0s 37us/step - loss: 1.1811 - acc: 0.4789\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 0s 37us/step - loss: 1.1799 - acc: 0.4726\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 0s 42us/step - loss: 1.1759 - acc: 0.4851\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.1782 - acc: 0.4720\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 0s 31us/step - loss: 1.1761 - acc: 0.4823\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 0s 32us/step - loss: 1.1751 - acc: 0.4794\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 0s 35us/step - loss: 1.1734 - acc: 0.4783\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.1757 - acc: 0.4806\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 0s 46us/step - loss: 1.1747 - acc: 0.4831\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 0s 39us/step - loss: 1.1750 - acc: 0.4849\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.1711 - acc: 0.4857\n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1710 - acc: 0.4863\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 0s 37us/step - loss: 1.1727 - acc: 0.4797\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1701 - acc: 0.4851\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 0s 38us/step - loss: 1.1722 - acc: 0.4863\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1728 - acc: 0.4786\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 0s 42us/step - loss: 1.1693 - acc: 0.4900\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1704 - acc: 0.4871\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.1680 - acc: 0.4860\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 0s 39us/step - loss: 1.1721 - acc: 0.4814\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 0s 48us/step - loss: 1.1682 - acc: 0.4863\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.1689 - acc: 0.4903\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1687 - acc: 0.4866\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 0s 43us/step - loss: 1.1669 - acc: 0.4851\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 0s 43us/step - loss: 1.1681 - acc: 0.4846\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1695 - acc: 0.4857\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 0s 46us/step - loss: 1.1667 - acc: 0.4829\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 0s 37us/step - loss: 1.1685 - acc: 0.4854\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 0s 41us/step - loss: 1.1694 - acc: 0.4800\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 0s 39us/step - loss: 1.1720 - acc: 0.4863\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 0s 47us/step - loss: 1.1678 - acc: 0.4846\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 0s 43us/step - loss: 1.1652 - acc: 0.4829\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 0s 42us/step - loss: 1.1678 - acc: 0.4849\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 0s 47us/step - loss: 1.1672 - acc: 0.4860\n",
      "--- 7.602008581161499 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=40, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_nn=model.predict(X_train_scaled);\n",
    "y_pred_test_nn=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [28 51 51 ... 51 51 51] [28 10 28 ... 51 75 51]\n",
      "(1050,) [28 51 51 ... 51 51 51] [28 51 51 ... 51 51 10]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x==0:\n",
    "        return 1;\n",
    "    elif x==1:\n",
    "        return 5;\n",
    "    elif x==2:\n",
    "        return 10;\n",
    "    elif x==3:\n",
    "        return 16;\n",
    "    elif x==4:\n",
    "        return 28;\n",
    "    elif x==5:\n",
    "        return 51;\n",
    "    elif x==6:\n",
    "        return 75;\n",
    "\n",
    "\n",
    "y_pred_train_nn_etiquetas=[];\n",
    "y_pred_test_nn_etiquetas=[];\n",
    "#print(len(y_pred_train_nn[0]))\n",
    "for i in range(3500):\n",
    "    posMax=6;\n",
    "    valMax=y_pred_train_nn[i][6]\n",
    "    for j in range(6):\n",
    "        if y_pred_train_nn[i][j] > valMax:\n",
    "            valMax=y_pred_train_nn[i][j];\n",
    "            posMax=j;\n",
    "            \n",
    "    y_pred_train_nn_etiquetas.append(f(posMax));\n",
    "    if i < 1050:\n",
    "        posMax=6;\n",
    "        valMax=y_pred_test_nn[i][6]\n",
    "        for j in range(6):\n",
    "            if y_pred_test_nn[i][j] > valMax:\n",
    "                valMax=y_pred_test_nn[i][j];\n",
    "                posMax=j;\n",
    "        y_pred_test_nn_etiquetas.append(f(posMax));   \n",
    "        \n",
    "y_pred_train_nn_etiquetas=np.asarray(y_pred_train_nn_etiquetas);\n",
    "y_pred_test_nn_etiquetas=np.asarray(y_pred_test_nn_etiquetas);\n",
    "\n",
    "print(y_pred_train_nn_etiquetas.shape,y_pred_train_nn_etiquetas,Y_train);\n",
    "print(y_pred_test_nn_etiquetas.shape,y_pred_test_nn_etiquetas, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  335.85685714285717\n",
      "ERROR MSE de test:  350.51428571428573\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_nn_etiquetas))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_nn_etiquetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregando $ metrics=[\"mae\"]$ a los parámetros de compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3500/3500 [==============================] - 1s 413us/step - loss: 1.4723 - mean_absolute_error: 0.2087\n",
      "Epoch 2/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.2192 - mean_absolute_error: 0.1823\n",
      "Epoch 3/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1987 - mean_absolute_error: 0.1804\n",
      "Epoch 4/40\n",
      "3500/3500 [==============================] - 0s 36us/step - loss: 1.1883 - mean_absolute_error: 0.1809\n",
      "Epoch 5/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1849 - mean_absolute_error: 0.1805\n",
      "Epoch 6/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1804 - mean_absolute_error: 0.1800\n",
      "Epoch 7/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1794 - mean_absolute_error: 0.1800\n",
      "Epoch 8/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1789 - mean_absolute_error: 0.1793\n",
      "Epoch 9/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1762 - mean_absolute_error: 0.1785\n",
      "Epoch 10/40\n",
      "3500/3500 [==============================] - 0s 55us/step - loss: 1.1772 - mean_absolute_error: 0.1796\n",
      "Epoch 11/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1773 - mean_absolute_error: 0.1795\n",
      "Epoch 12/40\n",
      "3500/3500 [==============================] - 0s 58us/step - loss: 1.1748 - mean_absolute_error: 0.1793\n",
      "Epoch 13/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1763 - mean_absolute_error: 0.1787\n",
      "Epoch 14/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1731 - mean_absolute_error: 0.1801\n",
      "Epoch 15/40\n",
      "3500/3500 [==============================] - 0s 54us/step - loss: 1.1739 - mean_absolute_error: 0.1787\n",
      "Epoch 16/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1740 - mean_absolute_error: 0.1786\n",
      "Epoch 17/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1730 - mean_absolute_error: 0.1795\n",
      "Epoch 18/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1712 - mean_absolute_error: 0.1786\n",
      "Epoch 19/40\n",
      "3500/3500 [==============================] - 0s 54us/step - loss: 1.1708 - mean_absolute_error: 0.1785\n",
      "Epoch 20/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1737 - mean_absolute_error: 0.1790\n",
      "Epoch 21/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1712 - mean_absolute_error: 0.1789\n",
      "Epoch 22/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1732 - mean_absolute_error: 0.1786\n",
      "Epoch 23/40\n",
      "3500/3500 [==============================] - 0s 54us/step - loss: 1.1767 - mean_absolute_error: 0.1789\n",
      "Epoch 24/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1714 - mean_absolute_error: 0.1783\n",
      "Epoch 25/40\n",
      "3500/3500 [==============================] - 0s 54us/step - loss: 1.1686 - mean_absolute_error: 0.1787\n",
      "Epoch 26/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1684 - mean_absolute_error: 0.1788\n",
      "Epoch 27/40\n",
      "3500/3500 [==============================] - 0s 54us/step - loss: 1.1697 - mean_absolute_error: 0.1796\n",
      "Epoch 28/40\n",
      "3500/3500 [==============================] - 0s 63us/step - loss: 1.1699 - mean_absolute_error: 0.1783\n",
      "Epoch 29/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1687 - mean_absolute_error: 0.1778\n",
      "Epoch 30/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1689 - mean_absolute_error: 0.1787\n",
      "Epoch 31/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1692 - mean_absolute_error: 0.1797\n",
      "Epoch 32/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1685 - mean_absolute_error: 0.1781\n",
      "Epoch 33/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1648 - mean_absolute_error: 0.1781\n",
      "Epoch 34/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1666 - mean_absolute_error: 0.1791\n",
      "Epoch 35/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1658 - mean_absolute_error: 0.1783\n",
      "Epoch 36/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1669 - mean_absolute_error: 0.1782\n",
      "Epoch 37/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1652 - mean_absolute_error: 0.1782\n",
      "Epoch 38/40\n",
      "3500/3500 [==============================] - 0s 45us/step - loss: 1.1662 - mean_absolute_error: 0.1788\n",
      "Epoch 39/40\n",
      "3500/3500 [==============================] - 0s 49us/step - loss: 1.1655 - mean_absolute_error: 0.1783\n",
      "Epoch 40/40\n",
      "3500/3500 [==============================] - 0s 40us/step - loss: 1.1702 - mean_absolute_error: 0.1785\n",
      "--- 8.666138172149658 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"mae\"])\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=40, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_nn=model.predict(X_train_scaled);\n",
    "y_pred_test_nn=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) [51 51 51 ... 51 51 51] [28 10 28 ... 51 75 51]\n",
      "(1050,) [51 51 51 ... 51 51 51] [28 51 51 ... 51 51 10]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x==0:\n",
    "        return 1;\n",
    "    elif x==1:\n",
    "        return 5;\n",
    "    elif x==2:\n",
    "        return 10;\n",
    "    elif x==3:\n",
    "        return 16;\n",
    "    elif x==4:\n",
    "        return 28;\n",
    "    elif x==5:\n",
    "        return 51;\n",
    "    elif x==6:\n",
    "        return 75;\n",
    "\n",
    "\n",
    "y_pred_train_nn_etiquetas=[];\n",
    "y_pred_test_nn_etiquetas=[];\n",
    "#print(len(y_pred_train_nn[0]))\n",
    "for i in range(3500):\n",
    "    posMax=6;\n",
    "    valMax=y_pred_train_nn[i][6]\n",
    "    for j in range(6):\n",
    "        if y_pred_train_nn[i][j] > valMax:\n",
    "            valMax=y_pred_train_nn[i][j];\n",
    "            posMax=j;\n",
    "            \n",
    "    y_pred_train_nn_etiquetas.append(f(posMax));\n",
    "    if i < 1050:\n",
    "        posMax=6;\n",
    "        valMax=y_pred_test_nn[i][6]\n",
    "        for j in range(6):\n",
    "            if y_pred_test_nn[i][j] > valMax:\n",
    "                valMax=y_pred_test_nn[i][j];\n",
    "                posMax=j;\n",
    "        y_pred_test_nn_etiquetas.append(f(posMax));   \n",
    "        \n",
    "y_pred_train_nn_etiquetas=np.asarray(y_pred_train_nn_etiquetas);\n",
    "y_pred_test_nn_etiquetas=np.asarray(y_pred_test_nn_etiquetas);\n",
    "\n",
    "print(y_pred_train_nn_etiquetas.shape,y_pred_train_nn_etiquetas,Y_train);\n",
    "print(y_pred_test_nn_etiquetas.shape,y_pred_test_nn_etiquetas, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  360.3222857142857\n",
      "ERROR MSE de test:  358.0933333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_nn_etiquetas))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_nn_etiquetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora con un árbol de decisión de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=10,criterion='gini',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  281.7934285714286\n",
      "ERROR MSE de test:  393.1457142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variaremos la profundidad máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=20,criterion='gini',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  85.15342857142858\n",
      "ERROR MSE de test:  493.4428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=30,criterion='gini',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  19.553142857142856\n",
      "ERROR MSE de test:  523.472380952381\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=8,criterion='gini',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  320.0185714285714\n",
      "ERROR MSE de test:  378.36380952380955\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=5,criterion='gini',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  333.62857142857143\n",
      "ERROR MSE de test:  365.9104761904762\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiando el criterio por $entropy$, y variando la profundidad.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  352.15171428571426\n",
      "ERROR MSE de test:  372.05619047619047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=5,criterion='entropy',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);\n",
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  358.82428571428574\n",
      "ERROR MSE de test:  364.1857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=4,criterion='entropy',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);\n",
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  311.4611428571429\n",
      "ERROR MSE de test:  392.13428571428574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=8,criterion='entropy',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);\n",
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR MSE de training:  268.93514285714286\n",
      "ERROR MSE de test:  410.0933333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree;\n",
    "model = Tree() ;\n",
    "model.set_params(max_depth=10,criterion='entropy',splitter='best');\n",
    "model.fit(X_train_scaled,Y_train);\n",
    "y_pred_train_tree=model.predict(X_train_scaled);\n",
    "y_pred_test_tree=model.predict(X_test_scaled);\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_tree))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con SVM para clasificación.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.774691343307495 seconds ---\n",
      "ERROR MSE de training:  387.69885714285715\n",
      "ERROR MSE de test:  401.35238095238094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=1,kernel='rbf')\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.6108217239379883 seconds ---\n",
      "ERROR MSE de training:  354.00714285714287\n",
      "ERROR MSE de test:  371.0390476190476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=1,kernel='rbf')\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.091035842895508 seconds ---\n",
      "ERROR MSE de training:  398.83257142857144\n",
      "ERROR MSE de test:  390.5628571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=0.1,kernel='rbf')\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.4388513565063477 seconds ---\n",
      "ERROR MSE de training:  368.6614285714286\n",
      "ERROR MSE de test:  368.82666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=0.1,kernel='rbf')\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.8593816757202148 seconds ---\n",
      "ERROR MSE de training:  411.2168571428571\n",
      "ERROR MSE de test:  395.3504761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=0.01,kernel='rbf')\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.1718966960906982 seconds ---\n",
      "ERROR MSE de training:  368.6614285714286\n",
      "ERROR MSE de test:  368.82666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=0.01,kernel='rbf')\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.422327280044556 seconds ---\n",
      "ERROR MSE de training:  366.078\n",
      "ERROR MSE de test:  387.1647619047619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=10,kernel='rbf')\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.032118797302246 seconds ---\n",
      "ERROR MSE de training:  348.2628571428571\n",
      "ERROR MSE de test:  363.5904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=10,kernel='rbf')\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.3757967948913574 seconds ---\n",
      "ERROR MSE de training:  388.88514285714285\n",
      "ERROR MSE de test:  435.70190476190476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=1,kernel='poly')\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.7274479866027832 seconds ---\n",
      "ERROR MSE de training:  368.6614285714286\n",
      "ERROR MSE de test:  368.82666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=1,kernel='poly')\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.6004409790039062 seconds ---\n",
      "ERROR MSE de training:  394.66857142857145\n",
      "ERROR MSE de test:  410.4895238095238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=0.1,kernel='poly')\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.4810547828674316 seconds ---\n",
      "ERROR MSE de training:  368.6614285714286\n",
      "ERROR MSE de test:  368.82666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=0.1,kernel='poly')\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.295992136001587 seconds ---\n",
      "ERROR MSE de training:  390.23657142857144\n",
      "ERROR MSE de test:  430.807619047619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=10,kernel='poly')\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.953841209411621 seconds ---\n",
      "ERROR MSE de training:  368.6614285714286\n",
      "ERROR MSE de test:  368.82666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM \n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import time\n",
    "start_time =time.time()\n",
    "model= SVM()\n",
    "model.set_params(C=10,kernel='poly')\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "y_pred_train_svm=model.predict(X_train_scaled);\n",
    "y_pred_test_svm=model.predict(X_test_scaled);\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"ERROR MSE de training: \", MSE(Y_train,y_pred_train_svm))\n",
    "print(\"ERROR MSE de test: \", MSE(Y_test,y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se experimenta con múltiples modelos variando sus parámetros, sin embargo, está muy lejos de llegar al error pedido. Esto lo atribuimos al hecho de que las representación usada y los atributos elegidos no son los óptimos para realizar buenas predicciones. Quizas se podria mejorar la representación, tomando otras clases como representativas, o directamente hacen falta más ejemplos. Otro motivo del alto error puede ser el que el hecho de tratar el problema como uno de clasificación, hace que no se permitan edades intermedias, de ahí que no se reduzcan tanto los errores MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL mínimo error de test se obtuvo con el siguiente modelo y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(y_onehot_train.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(X_train_scaled, y_onehot_train, epochs=15, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteniéndose:  \n",
    "    \n",
    "\n",
    "ERROR MSE de training:  341.114  \n",
    "ERROR MSE de test:  348.1485714285714  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ayuda:\n",
    "\n",
    "Para problemas de clasificación de múltiples clases, la red neuronal de *keras* necesita una represnetacion *one hot vector* similar a lo comentado en la sección 2, por lo que será necesario transformar/codificar las edades a etiquetas categóricas, donde cada columna del vector representará una categoría. Por ejemplo, si existen tres categorías (perro, gato, ratón), la categoría perro puede ser codificada como [1,0,0], y la categoría ratón puede ser codificada como [0,0,1]. Para ésto la librería *keras* nos ayuda:\n",
    "\n",
    "<div class=\"alert alert-warning\"> Recuerde que si trabaja el problema como clasificación deberá invertir la transformación de codificación de las edades a clases, para así poder evaluar el MSE </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recuerde que:* Si encuentra que la métrica evaluadora le perjudica puede acudir a otras para entender el qué está pasando con su modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] Keras: Deep Learning library for Theano and TensorFlow. https://keras.io/  \n",
    "[2] http://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html  \n",
    "[3] https://en.wikipedia.org/wiki/Kernel_method  \n",
    "[4] http://scikit-learn.org/stable/modules/multiclass.html  \n",
    "[5] Tsoumakas, G., & Katakis, I. (2007). *Multi-label classification: An overview*. International Journal of Data Warehousing and Mining (IJDWM), 3(3), 1-13.  \n",
    "[6] https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-6-feature-engineering-and-feature-selection-8b94f870706a  \n",
    "[7] Bishop, C. M. (2006). *Pattern recognition and machine learning (information science and statistics)* springer-verlag new york. Inc. Secaucus, NJ, USA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
